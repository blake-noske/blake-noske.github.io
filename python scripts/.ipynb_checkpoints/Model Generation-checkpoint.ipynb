{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3711e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import sklearn\n",
    "import pickle\n",
    "import os\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV, cross_val_score,TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba621a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "match_results = pd.read_csv('afl_match_results_cleaned.csv')\n",
    "\n",
    "# Define the features and the target variable\n",
    "weather_dummies = pd.get_dummies(match_results['weather.weatherType'])\n",
    "X = match_results.drop(columns=['match.homeTeam.name', 'match.awayTeam.name','venue.name','Margin','Result','weather.weatherType']).astype('float64')  # Drop irrelevant columns\n",
    "X = pd.concat([X, weather_dummies], axis=1)\n",
    "y = match_results['Result']  # BW, LW, D, LL, BL\n",
    "\n",
    "# Assuming 'weather_columns' is a list of your dummy weather variables\n",
    "weather_columns = weather_dummies.columns  # Replace with actual weather columns\n",
    "discrete_columns = ['Home.Team.Venue.Win.Streak', 'Away.Team.Venue.Win.Streak','Home.Win.Streak'] \n",
    "continuous_columns = [col for col in X.columns if col not in weather_columns and col not in discrete_columns]\n",
    "\n",
    "# ColumnTransformer to apply StandardScaler only to continuous features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), continuous_columns),\n",
    "        ('disc', MinMaxScaler(), discrete_columns),\n",
    "        ('weather', 'passthrough', weather_columns)  # Weather columns are passed through unchanged\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target variable\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "cutoff_index = int(0.8 * len(match_results))\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "\n",
    "y_train = encoder.fit_transform(y)\n",
    "#y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "\n",
    "# Standardize the features\n",
    "X_train = preprocessor.fit_transform(X)\n",
    "#X_test = preprocessor.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07026fcc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Run at beginning of season"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b2fdd71-9186-44e4-9536-41d7503c0444",
   "metadata": {},
   "source": [
    "# TimeSeriesSplit for time-aware cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# Function to create the Keras model\n",
    "def create_model(optimizer='adam', dropout_rate=0.3, neurons=64, learn_rate=0.01):\n",
    "    model = Sequential([\n",
    "        Dense(neurons, kernel_initializer='he_uniform', activation='relu', kernel_regularizer=l2(0.001), input_dim=X_train.shape[1]),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(32, kernel_initializer='he_uniform', activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(16, kernel_initializer='he_uniform', activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(5, kernel_initializer='he_uniform', activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learn_rate, name=optimizer), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Example: Cross-validate Neural Network (Keras) base model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "nn_param_grid = {\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [50],\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'dropout_rate': [0.2, 0.3, 0.5],\n",
    "    'neurons': [32, 64, 128],\n",
    "    'learn_rate': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_nn = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=nn_param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model using GridSearchCV\n",
    "grid_search_nn.fit(X_train, y_train)\n",
    "\n",
    "# Best Neural Network model\n",
    "best_nn_model = grid_search_nn.best_estimator_\n",
    "print(f\"Best NN params: {grid_search_nn.best_params_}\")\n",
    "print(f\"Best NN accuracy: {grid_search_nn.best_score_}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cf6e65e-ba1c-4952-b6e5-126c22fa11ce",
   "metadata": {},
   "source": [
    "# Example: Cross-validate Random Forest base model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best Random Forest model\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "print(f\"Best RF params: {grid_search_rf.best_params_}\")\n",
    "print(f\"Best RF accuracy: {grid_search_rf.best_score_}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3e3778f-3407-474a-ab88-1e696a550538",
   "metadata": {},
   "source": [
    "# Define the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Grid search for hyperparameter tuning\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Best XGBoost model\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "print(f\"Best XGBoost params: {grid_search_xgb.best_params_}\")\n",
    "print(f\"Best XGBoost accuracy: {grid_search_xgb.best_score_}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f7ceb92-6fb4-46dd-b4de-4dc66f2ff359",
   "metadata": {},
   "source": [
    "# Function to create the Keras model\n",
    "def create_model(optimizer='adam', dropout_rate=0.3, neurons=64, learn_rate=0.01):\n",
    "    model = Sequential([\n",
    "        Dense(128, kernel_initializer='he_uniform', activation='relu', kernel_regularizer=l2(0.001), input_dim=X_train.shape[1]),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, kernel_initializer='he_uniform', activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(16, kernel_initializer='he_uniform', activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(5, kernel_initializer='he_uniform', activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, name='adam'), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Example: Cross-validate Neural Network (Keras) base model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Initialize base models\n",
    "nn_model = KerasClassifier(build_fn=lambda: create_model(X_train.shape[1]), epochs=100, batch_size=32, verbose=0)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=20, min_samples_split=5)\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', colsample_bytree=0.8,\n",
    "                          learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8)\n",
    "\n",
    "# Fit the base models\n",
    "nn_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "rf_predictions_train = rf_model.predict_proba(X_train)\n",
    "xgb_predictions_train = xgb_model.predict_proba(X_train)\n",
    "nn_predictions_train = nn_model.predict_proba(X_train)\n",
    "\n",
    "meta_train_X = np.hstack([rf_predictions_train, xgb_predictions_train, nn_predictions_train])\n",
    "meta_train_y = y_train  # Your training labels\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Set up the TimeSeriesSplit for time-aware cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Define the hyperparameters to tune for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'solver': ['liblinear', 'lbfgs'],  # Different solvers for logistic regression\n",
    "    'max_iter': [100, 200]  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=meta_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='accuracy',  # You can change this to 'f1', 'roc_auc', etc., depending on your metric of choice\n",
    "    verbose=1,\n",
    "    n_jobs=-1  # Use all available cores for parallel processing\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search using GridSearchCV\n",
    "grid_search.fit(meta_train_X, meta_train_y)\n",
    "\n",
    "# Get the best meta-model from the grid search\n",
    "best_meta_model = grid_search.best_estimator_\n",
    "\n",
    "# Output the best hyperparameters\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e29247",
   "metadata": {},
   "source": [
    "### Continue programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b81a41-5d52-4145-aa95-ab706fda0d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 3ms/step\n",
      "13/13 [==============================] - 0s 4ms/step\n",
      "Average Accuracy from TimeSeriesSplit CV: 0.7813\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network model function\n",
    "def create_simple_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, kernel_initializer='he_uniform', activation='relu', kernel_regularizer=l2(0.001), input_dim=X_train.shape[1]),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, kernel_initializer='he_uniform', activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(16, kernel_initializer='he_uniform', activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(5, kernel_initializer='he_uniform', activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, name='adam'), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize base models\n",
    "nn_model = KerasClassifier(build_fn=lambda: create_simple_model(X_train.shape[1]), epochs=100, batch_size=32, verbose=0)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=20, min_samples_split=5)\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', colsample_bytree=0.8,\n",
    "                          learning_rate=0.2, max_depth=3, n_estimators=100, subsample=0.8)\n",
    "\n",
    "# Fit the base models\n",
    "rf_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "fold_accuracies = []\n",
    "\n",
    "for train_index, val_index in tscv.split(X_train):\n",
    "    X_t, X_val = X_train[train_index], X_train[val_index]\n",
    "    y_t, y_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # Re-instantiate KerasClassifier for each fold with proper input_dim\n",
    "    nn_model = KerasClassifier(build_fn=lambda: create_simple_model(X_train.shape[1]), epochs=100, batch_size=32, verbose=0)\n",
    "    \n",
    "    # Fit base models\n",
    "    rf_model.fit(X_t, y_t)\n",
    "    xgb_model.fit(X_t, y_t)\n",
    "    \n",
    "    # Get predictions from the neural network for the validation fold\n",
    "    nn_model.fit(X_t, y_t)  # Fit the neural network on the training fold\n",
    "    nn_predictions_val = nn_model.predict_proba(X_val)  # Get predictions for the validation fold\n",
    "    \n",
    "    # Get predictions from the other base models for the validation fold\n",
    "    rf_predictions_val = rf_model.predict_proba(X_val)\n",
    "    xgb_predictions_val = xgb_model.predict_proba(X_val)\n",
    "    \n",
    "    # Combine predictions from all models for stacking\n",
    "    meta_features_val = np.hstack([rf_predictions_val, xgb_predictions_val, nn_predictions_val])\n",
    "    \n",
    "    # Train a meta-model (LogisticRegression in this case) on the combined predictions\n",
    "    meta_model = LogisticRegression(C=100, max_iter=100, solver='liblinear')\n",
    "    meta_model.fit(meta_features_val, y_val)\n",
    "    \n",
    "    # Evaluate the meta-model on the validation set\n",
    "    meta_predictions_val = meta_model.predict(meta_features_val)\n",
    "    accuracy = accuracy_score(y_val, meta_predictions_val)\n",
    "    fold_accuracies.append(accuracy)\n",
    "\n",
    "# After cross-validation, calculate the average accuracy\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "print(f'Average Accuracy from TimeSeriesSplit CV: {average_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b6b49b0-b086-4bb6-ab36-4b72742e1736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 3ms/step\n",
      "Final ensemble model trained on the full dataset.\n"
     ]
    }
   ],
   "source": [
    "# Combine scaled features for the entire dataset\n",
    "X_full_scaled = preprocessor.fit_transform(X)\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Train base models on the full dataset\n",
    "rf_model.fit(X_full_scaled, y_encoded)\n",
    "xgb_model.fit(X_full_scaled, y_encoded)\n",
    "nn_model_full = KerasClassifier(build_fn=lambda: create_simple_model(X_full_scaled.shape[1]), \n",
    "                                epochs=100, batch_size=32, verbose=0)\n",
    "nn_model_full.fit(X_full_scaled, y_encoded)\n",
    "\n",
    "# Generate predictions (probabilities) for stacking\n",
    "rf_predictions_full = rf_model.predict_proba(X_full_scaled)\n",
    "xgb_predictions_full = xgb_model.predict_proba(X_full_scaled)\n",
    "nn_predictions_full = nn_model_full.predict_proba(X_full_scaled)\n",
    "\n",
    "# Stack predictions to form meta-features\n",
    "meta_features_full = np.hstack([rf_predictions_full, xgb_predictions_full, nn_predictions_full])\n",
    "\n",
    "# Train meta-model (Logistic Regression) on the full dataset's meta-features\n",
    "meta_model_full = LogisticRegression()\n",
    "meta_model_full.fit(meta_features_full, y_encoded)\n",
    "\n",
    "print(\"Final ensemble model trained on the full dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8269cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully.\n"
     ]
    }
   ],
   "source": [
    "#final_model.save('final_model.h5')\n",
    "with open('encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder, f)\n",
    "with open('preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "with open('accuracy.pkl', 'wb') as f:\n",
    "    pickle.dump(average_accuracy, f)\n",
    "\n",
    "# Save RandomForest model\n",
    "joblib.dump(rf_model, 'rf_model.pkl')\n",
    "\n",
    "# Save XGBoost model\n",
    "joblib.dump(xgb_model, 'xgb_model.pkl')\n",
    "\n",
    "# Save the neural network model\n",
    "save_model(nn_model_full.model, 'nn_model.h5')\n",
    "\n",
    "# Save the meta-model (Logistic Regression)\n",
    "joblib.dump(meta_model_full, 'meta_model.pkl')\n",
    "\n",
    "print(\"Models saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873dfce3-cdcb-437c-baa8-fb8664afd355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb3c28-58bc-488e-8269-b1b2779bbba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d229b-5516-42a0-a40b-44cafd814f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bede696-2dba-42b1-bf21-7955a125c941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping feature: match.homeTeam.Total.kicks\n",
      "Dropping feature: match.homeTeam.Total.handballs\n",
      "Dropping feature: match.homeTeam.Total.disposals\n",
      "Dropping feature: match.homeTeam.Total.marks\n",
      "Dropping feature: match.homeTeam.Total.bounces\n",
      "Dropping feature: match.homeTeam.Total.tackles\n",
      "Dropping feature: match.homeTeam.Total.contestedPossessions\n",
      "Dropping feature: match.homeTeam.Total.uncontestedPossessions\n",
      "Dropping feature: match.homeTeam.Total.totalPossessions\n",
      "Dropping feature: match.homeTeam.Total.inside50s\n",
      "Dropping feature: match.homeTeam.Total.marksInside50\n",
      "Dropping feature: match.homeTeam.Total.contestedMarks\n",
      "Dropping feature: match.homeTeam.Total.hitouts\n",
      "Dropping feature: match.homeTeam.Total.onePercenters\n",
      "Dropping feature: match.homeTeam.Total.disposalEfficiency\n",
      "Dropping feature: match.homeTeam.Total.clangers\n",
      "Dropping feature: match.homeTeam.Total.freesAgainst\n",
      "Dropping feature: match.homeTeam.Total.rebound50s\n",
      "Dropping feature: match.homeTeam.Total.turnovers\n",
      "Dropping feature: match.homeTeam.Total.intercepts\n",
      "Dropping feature: match.homeTeam.Total.tacklesInside50\n",
      "Dropping feature: match.homeTeam.Total.metresGained\n",
      "Dropping feature: match.homeTeam.Total.clearances.centreClearances\n",
      "Dropping feature: match.homeTeam.Total.clearances.stoppageClearances\n",
      "Dropping feature: match.homeTeam.Total.clearances.totalClearances\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.effectiveKicks\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.kickEfficiency\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.kickToHandballRatio\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.effectiveDisposals\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.marksOnLead\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.interceptMarks\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.contestedPossessionRate\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.hitoutsToAdvantage\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.hitoutWinPercentage\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.hitoutToAdvantageRate\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.groundBallGets\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.f50GroundBallGets\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.scoreLaunches\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.pressureActs\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.defHalfPressureActs\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.spoils\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.ruckContests\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.contestDefOneOnOnes\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.contestDefLosses\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.contestDefLossPercentage\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.contestOffOneOnOnes\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.contestOffWins\n",
      "Dropping feature: match.homeTeam.Total.extendedStats.contestOffWinsPercentage\n",
      "Dropping feature: Home.Elo\n",
      "Dropping feature: Home.Team.Venue.Win.Streak\n",
      "Dropping feature: Home.Team.Form\n",
      "Dropping feature: match.awayTeam.Total.kicks\n",
      "Dropping feature: match.awayTeam.Total.handballs\n",
      "Dropping feature: match.awayTeam.Total.disposals\n",
      "Dropping feature: match.awayTeam.Total.marks\n",
      "Dropping feature: match.awayTeam.Total.bounces\n",
      "Dropping feature: match.awayTeam.Total.tackles\n",
      "Dropping feature: match.awayTeam.Total.contestedPossessions\n",
      "Dropping feature: match.awayTeam.Total.uncontestedPossessions\n",
      "Dropping feature: match.awayTeam.Total.totalPossessions\n",
      "Dropping feature: match.awayTeam.Total.inside50s\n",
      "Dropping feature: match.awayTeam.Total.marksInside50\n",
      "Dropping feature: match.awayTeam.Total.contestedMarks\n",
      "Dropping feature: match.awayTeam.Total.hitouts\n",
      "Dropping feature: match.awayTeam.Total.onePercenters\n",
      "Dropping feature: match.awayTeam.Total.disposalEfficiency\n",
      "Dropping feature: match.awayTeam.Total.clangers\n",
      "Dropping feature: match.awayTeam.Total.freesAgainst\n",
      "Dropping feature: match.awayTeam.Total.rebound50s\n",
      "Dropping feature: match.awayTeam.Total.turnovers\n",
      "Dropping feature: match.awayTeam.Total.intercepts\n",
      "Dropping feature: match.awayTeam.Total.tacklesInside50\n",
      "Dropping feature: match.awayTeam.Total.metresGained\n",
      "Dropping feature: match.awayTeam.Total.clearances.centreClearances\n",
      "Dropping feature: match.awayTeam.Total.clearances.stoppageClearances\n",
      "Dropping feature: match.awayTeam.Total.clearances.totalClearances\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.effectiveKicks\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.kickEfficiency\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.kickToHandballRatio\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.effectiveDisposals\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.marksOnLead\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.interceptMarks\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.contestedPossessionRate\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.hitoutsToAdvantage\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.hitoutWinPercentage\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.hitoutToAdvantageRate\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.groundBallGets\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.f50GroundBallGets\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.scoreLaunches\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.pressureActs\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.defHalfPressureActs\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.spoils\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.ruckContests\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.contestDefOneOnOnes\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.contestDefLosses\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.contestDefLossPercentage\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.contestOffOneOnOnes\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.contestOffWins\n",
      "Dropping feature: match.awayTeam.Total.extendedStats.contestOffWinsPercentage\n",
      "Dropping feature: Away.Elo\n",
      "Dropping feature: Away.Team.Venue.Win.Streak\n",
      "Dropping feature: Away.Team.Form\n",
      "Dropping feature: Home.Win.Streak\n",
      "Dropping feature: CLEAR_NIGHT\n",
      "Dropping feature: MOSTLY_SUNNY\n",
      "Dropping feature: OVERCAST\n",
      "Dropping feature: RAIN\n",
      "Dropping feature: SUNNY\n",
      "Dropping feature: THUNDERSTORMS\n",
      "Dropping feature: WINDY\n",
      "                                              Feature  Importance\n",
      "67                  match.awayTeam.Total.freesAgainst    0.018135\n",
      "37   match.homeTeam.Total.extendedStats.scoreLaunches    0.007772\n",
      "21                  match.homeTeam.Total.metresGained    0.007772\n",
      "89    match.awayTeam.Total.extendedStats.pressureActs    0.005181\n",
      "36  match.homeTeam.Total.extendedStats.f50GroundBa...    0.005181\n",
      "..                                                ...         ...\n",
      "32  match.homeTeam.Total.extendedStats.hitoutsToAd...   -0.015544\n",
      "71               match.awayTeam.Total.tacklesInside50   -0.015544\n",
      "13                 match.homeTeam.Total.onePercenters   -0.015544\n",
      "83  match.awayTeam.Total.extendedStats.hitoutsToAd...   -0.018135\n",
      "48                                           Home.Elo   -0.018135\n",
      "\n",
      "[110 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def drop_column_importance(ensemble_model, X_train, y_train, X_val, y_val, features):\n",
    "    # Step 1: Train the model with all features and calculate baseline performance\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    baseline_accuracy = accuracy_score(y_val, ensemble_model.predict(X_val))\n",
    "\n",
    "    importances = {}\n",
    "\n",
    "    # Step 2: For each feature, drop it, retrain the model, and calculate new performance\n",
    "    for feature in features:\n",
    "        print(f\"Dropping feature: {feature}\")\n",
    "        \n",
    "        # Drop the feature from the training and validation sets\n",
    "        X_train_dropped = X_train.drop(columns=[feature])\n",
    "        X_val_dropped = X_val.drop(columns=[feature])\n",
    "        \n",
    "        # Re-train the ensemble model without this feature\n",
    "        # Generate predictions (probabilities) for stacking\n",
    "        rf_pred_dropped = rf_model.predict_proba(X_train_dropped)\n",
    "        xgb_pred_dropped = xgb_model.predict_proba(X_train_dropped)\n",
    "        nn_pred_dropped = nn_model_full.predict_proba(X_train_dropped)\n",
    "\n",
    "        # Stack predictions to form meta-features\n",
    "        meta_feat_dropped = np.hstack([rf_pred_dropped, xgb_pred_dropped, nn_pred_dropped])\n",
    "        \n",
    "        ensemble_model.fit(meta_feat_dropped, y_train)\n",
    "        \n",
    "        # Calculate accuracy without this feature\n",
    "        # Generate predictions (probabilities) for stacking\n",
    "        rf_pred_dropped = rf_model.predict_proba(X_val_dropped)\n",
    "        xgb_pred_dropped = xgb_model.predict_proba(X_val_dropped)\n",
    "        nn_pred_dropped = nn_model_full.predict_proba(X_val_dropped)\n",
    "\n",
    "        # Stack predictions to form meta-features\n",
    "        meta_feat_dropped = np.hstack([rf_pred_dropped, xgb_pred_dropped, nn_pred_dropped])\n",
    "        \n",
    "        new_accuracy = accuracy_score(y_val, ensemble_model.predict(meta_feat_dropped))\n",
    "        \n",
    "        # Store the performance drop (baseline - new accuracy)\n",
    "        importances[feature] = baseline_accuracy - new_accuracy\n",
    "\n",
    "    return importances\n",
    "\n",
    "# Assuming you have X_train, y_train, X_val, y_val, and the ensemble_model already set up\n",
    "feature_names = X.columns  # Adjust if you're using a numpy array\n",
    "X_t_df = pd.DataFrame(X_t,columns = feature_names)\n",
    "X_val_df = pd.DataFrame(X_val,columns = feature_names)\n",
    "\n",
    "feature_importances = drop_column_importance(meta_model_full, X_t_df, y_t, X_val_df, y_val, feature_names)\n",
    "\n",
    "# Convert to a DataFrame for easier viewing\n",
    "import pandas as pd\n",
    "importance_df = pd.DataFrame(list(feature_importances.items()), columns=['Feature', 'Importance'])\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display feature importance\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d34aea2-fa63-4626-85c0-87f45811ed74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1932, 110)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4d6205b-9526-407f-a7e9-8e16185bdf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match.homeTeam.Total.kicks</th>\n",
       "      <th>match.homeTeam.Total.handballs</th>\n",
       "      <th>match.homeTeam.Total.disposals</th>\n",
       "      <th>match.homeTeam.Total.marks</th>\n",
       "      <th>match.homeTeam.Total.bounces</th>\n",
       "      <th>match.homeTeam.Total.tackles</th>\n",
       "      <th>match.homeTeam.Total.contestedPossessions</th>\n",
       "      <th>match.homeTeam.Total.uncontestedPossessions</th>\n",
       "      <th>match.homeTeam.Total.totalPossessions</th>\n",
       "      <th>match.homeTeam.Total.inside50s</th>\n",
       "      <th>...</th>\n",
       "      <th>Away.Team.Venue.Win.Streak</th>\n",
       "      <th>Away.Team.Form</th>\n",
       "      <th>Home.Win.Streak</th>\n",
       "      <th>CLEAR_NIGHT</th>\n",
       "      <th>MOSTLY_SUNNY</th>\n",
       "      <th>OVERCAST</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>SUNNY</th>\n",
       "      <th>THUNDERSTORMS</th>\n",
       "      <th>WINDY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008218</td>\n",
       "      <td>0.956199</td>\n",
       "      <td>0.674818</td>\n",
       "      <td>-0.106054</td>\n",
       "      <td>0.574860</td>\n",
       "      <td>0.419987</td>\n",
       "      <td>0.952502</td>\n",
       "      <td>0.261106</td>\n",
       "      <td>0.617220</td>\n",
       "      <td>-0.140363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.118153</td>\n",
       "      <td>0.956199</td>\n",
       "      <td>2.466803</td>\n",
       "      <td>1.938499</td>\n",
       "      <td>0.188621</td>\n",
       "      <td>0.910007</td>\n",
       "      <td>0.893811</td>\n",
       "      <td>2.047490</td>\n",
       "      <td>2.197522</td>\n",
       "      <td>1.768899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.649572</td>\n",
       "      <td>1.808578</td>\n",
       "      <td>2.217916</td>\n",
       "      <td>1.159622</td>\n",
       "      <td>0.574860</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.632157</td>\n",
       "      <td>2.100030</td>\n",
       "      <td>1.631444</td>\n",
       "      <td>1.095042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.267379</td>\n",
       "      <td>1.169294</td>\n",
       "      <td>0.973482</td>\n",
       "      <td>0.964902</td>\n",
       "      <td>0.381740</td>\n",
       "      <td>-0.210039</td>\n",
       "      <td>-0.045246</td>\n",
       "      <td>1.154298</td>\n",
       "      <td>1.018192</td>\n",
       "      <td>-0.926529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.510105</td>\n",
       "      <td>-0.819590</td>\n",
       "      <td>-0.868280</td>\n",
       "      <td>-0.446813</td>\n",
       "      <td>1.926698</td>\n",
       "      <td>-0.070033</td>\n",
       "      <td>-0.338702</td>\n",
       "      <td>-0.894790</td>\n",
       "      <td>-0.939495</td>\n",
       "      <td>-0.814220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>0.872088</td>\n",
       "      <td>-0.357885</td>\n",
       "      <td>0.251711</td>\n",
       "      <td>1.403021</td>\n",
       "      <td>-0.583858</td>\n",
       "      <td>-1.820104</td>\n",
       "      <td>-0.514775</td>\n",
       "      <td>0.444998</td>\n",
       "      <td>0.192661</td>\n",
       "      <td>1.431971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>-0.855653</td>\n",
       "      <td>-0.073759</td>\n",
       "      <td>-0.544727</td>\n",
       "      <td>-1.177010</td>\n",
       "      <td>-0.776978</td>\n",
       "      <td>0.069973</td>\n",
       "      <td>0.013445</td>\n",
       "      <td>-0.710898</td>\n",
       "      <td>-0.632870</td>\n",
       "      <td>-1.038839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>0.396959</td>\n",
       "      <td>0.636557</td>\n",
       "      <td>0.674818</td>\n",
       "      <td>-0.008694</td>\n",
       "      <td>-0.004499</td>\n",
       "      <td>0.980009</td>\n",
       "      <td>0.248209</td>\n",
       "      <td>0.444998</td>\n",
       "      <td>0.499287</td>\n",
       "      <td>0.308875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>-0.337331</td>\n",
       "      <td>1.204810</td>\n",
       "      <td>0.649930</td>\n",
       "      <td>-0.544173</td>\n",
       "      <td>-0.970097</td>\n",
       "      <td>-0.490050</td>\n",
       "      <td>1.069884</td>\n",
       "      <td>0.392457</td>\n",
       "      <td>0.782326</td>\n",
       "      <td>0.758114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>2.211088</td>\n",
       "      <td>-0.713043</td>\n",
       "      <td>0.774373</td>\n",
       "      <td>1.743780</td>\n",
       "      <td>-0.583858</td>\n",
       "      <td>-0.910067</td>\n",
       "      <td>0.952502</td>\n",
       "      <td>0.497539</td>\n",
       "      <td>0.829499</td>\n",
       "      <td>2.891995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1932 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      match.homeTeam.Total.kicks  match.homeTeam.Total.handballs  \\\n",
       "0                       0.008218                        0.956199   \n",
       "1                       3.118153                        0.956199   \n",
       "2                       1.649572                        1.808578   \n",
       "3                       0.267379                        1.169294   \n",
       "4                      -0.510105                       -0.819590   \n",
       "...                          ...                             ...   \n",
       "1927                    0.872088                       -0.357885   \n",
       "1928                   -0.855653                       -0.073759   \n",
       "1929                    0.396959                        0.636557   \n",
       "1930                   -0.337331                        1.204810   \n",
       "1931                    2.211088                       -0.713043   \n",
       "\n",
       "      match.homeTeam.Total.disposals  match.homeTeam.Total.marks  \\\n",
       "0                           0.674818                   -0.106054   \n",
       "1                           2.466803                    1.938499   \n",
       "2                           2.217916                    1.159622   \n",
       "3                           0.973482                    0.964902   \n",
       "4                          -0.868280                   -0.446813   \n",
       "...                              ...                         ...   \n",
       "1927                        0.251711                    1.403021   \n",
       "1928                       -0.544727                   -1.177010   \n",
       "1929                        0.674818                   -0.008694   \n",
       "1930                        0.649930                   -0.544173   \n",
       "1931                        0.774373                    1.743780   \n",
       "\n",
       "      match.homeTeam.Total.bounces  match.homeTeam.Total.tackles  \\\n",
       "0                         0.574860                      0.419987   \n",
       "1                         0.188621                      0.910007   \n",
       "2                         0.574860                     -0.000030   \n",
       "3                         0.381740                     -0.210039   \n",
       "4                         1.926698                     -0.070033   \n",
       "...                            ...                           ...   \n",
       "1927                     -0.583858                     -1.820104   \n",
       "1928                     -0.776978                      0.069973   \n",
       "1929                     -0.004499                      0.980009   \n",
       "1930                     -0.970097                     -0.490050   \n",
       "1931                     -0.583858                     -0.910067   \n",
       "\n",
       "      match.homeTeam.Total.contestedPossessions  \\\n",
       "0                                      0.952502   \n",
       "1                                      0.893811   \n",
       "2                                     -0.632157   \n",
       "3                                     -0.045246   \n",
       "4                                     -0.338702   \n",
       "...                                         ...   \n",
       "1927                                  -0.514775   \n",
       "1928                                   0.013445   \n",
       "1929                                   0.248209   \n",
       "1930                                   1.069884   \n",
       "1931                                   0.952502   \n",
       "\n",
       "      match.homeTeam.Total.uncontestedPossessions  \\\n",
       "0                                        0.261106   \n",
       "1                                        2.047490   \n",
       "2                                        2.100030   \n",
       "3                                        1.154298   \n",
       "4                                       -0.894790   \n",
       "...                                           ...   \n",
       "1927                                     0.444998   \n",
       "1928                                    -0.710898   \n",
       "1929                                     0.444998   \n",
       "1930                                     0.392457   \n",
       "1931                                     0.497539   \n",
       "\n",
       "      match.homeTeam.Total.totalPossessions  match.homeTeam.Total.inside50s  \\\n",
       "0                                  0.617220                       -0.140363   \n",
       "1                                  2.197522                        1.768899   \n",
       "2                                  1.631444                        1.095042   \n",
       "3                                  1.018192                       -0.926529   \n",
       "4                                 -0.939495                       -0.814220   \n",
       "...                                     ...                             ...   \n",
       "1927                               0.192661                        1.431971   \n",
       "1928                              -0.632870                       -1.038839   \n",
       "1929                               0.499287                        0.308875   \n",
       "1930                               0.782326                        0.758114   \n",
       "1931                               0.829499                        2.891995   \n",
       "\n",
       "      ...  Away.Team.Venue.Win.Streak  Away.Team.Form  Home.Win.Streak  \\\n",
       "0     ...                    0.294118        0.461538             0.48   \n",
       "1     ...                    0.411765        0.423077             0.48   \n",
       "2     ...                    0.382353        0.423077             0.48   \n",
       "3     ...                    0.294118        0.423077             0.48   \n",
       "4     ...                    0.382353        0.461538             0.48   \n",
       "...   ...                         ...             ...              ...   \n",
       "1927  ...                    0.411765        0.384615             0.56   \n",
       "1928  ...                    0.323529        0.346154             0.32   \n",
       "1929  ...                    0.441176        0.269231             0.44   \n",
       "1930  ...                    0.382353        0.615385             0.40   \n",
       "1931  ...                    0.382353        0.269231             0.60   \n",
       "\n",
       "      CLEAR_NIGHT  MOSTLY_SUNNY  OVERCAST  RAIN  SUNNY  THUNDERSTORMS  WINDY  \n",
       "0             1.0           0.0       0.0   0.0    0.0            0.0    0.0  \n",
       "1             1.0           0.0       0.0   0.0    0.0            0.0    0.0  \n",
       "2             0.0           0.0       1.0   0.0    0.0            0.0    0.0  \n",
       "3             0.0           0.0       1.0   0.0    0.0            0.0    0.0  \n",
       "4             0.0           1.0       0.0   0.0    0.0            0.0    0.0  \n",
       "...           ...           ...       ...   ...    ...            ...    ...  \n",
       "1927          0.0           1.0       0.0   0.0    0.0            0.0    0.0  \n",
       "1928          0.0           1.0       0.0   0.0    0.0            0.0    0.0  \n",
       "1929          0.0           0.0       0.0   1.0    0.0            0.0    0.0  \n",
       "1930          0.0           0.0       0.0   1.0    0.0            0.0    0.0  \n",
       "1931          0.0           1.0       0.0   0.0    0.0            0.0    0.0  \n",
       "\n",
       "[1932 rows x 110 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_t,columns = feature_names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
