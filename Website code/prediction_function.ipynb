{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f6a61f-b638-4f49-b6a1-eebdd3aa1344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e03146d-4cc5-4958-b829-9fa15e1731a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_wd():\n",
    "    # Get the GitHub Actions workspace directory\n",
    "    workspace = os.getenv('GITHUB_WORKSPACE', '.')\n",
    "    \n",
    "    # Set the working directory to the folder where the data resides\n",
    "    cleaned_data = os.path.join(workspace, 'cleaned data')\n",
    "    website_code = os.path.join(workspace, 'Website code')\n",
    "    return cleaned_data,website_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f75e7fe9-8de6-4298-9973-b4aa9aa14b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_decimals_up(number:float, decimals:int=2):\n",
    "    \"\"\"\n",
    "    Returns a value rounded up to a specific number of decimal places.\n",
    "    \"\"\"\n",
    "    if not isinstance(decimals, int):\n",
    "        raise TypeError(\"decimal places must be an integer\")\n",
    "    elif decimals < 0:\n",
    "        raise ValueError(\"decimal places has to be 0 or more\")\n",
    "    elif decimals == 0:\n",
    "        return math.ceil(number)\n",
    "\n",
    "    factor = 10 ** decimals\n",
    "    return math.ceil(number * factor) / factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c6101a7-755b-4e1d-81ac-baf77074642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    os.chdir(cleaned_data)\n",
    "    match_results = pd.read_csv('afl_match_results_cleaned.csv')\n",
    "    team_stats = pd.read_csv('afl_team_stats_cleaned.csv')\n",
    "    win_streaks = pd.read_csv('afl_team_streaks_cleaned.csv',index_col=0)\n",
    "    venue_streaks = pd.read_csv('afl_venue_streaks_cleaned.csv',index_col=0)\n",
    "    team_form = pd.read_csv('afl_team_form_cleaned.csv',index_col=0)\n",
    "    fixture = pd.read_csv('afl_fixture_cleaned.csv',index_col=0)\n",
    "    os.chdir(website_code)\n",
    "    return match_results,team_stats,win_streaks,venue_streaks,team_form,fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab6152c-9ae6-4079-bdef-66b47b9c824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(home_team, away_team, venue,weather):\n",
    "    with open('preprocessor.pkl', 'rb') as f:\n",
    "        preprocessor = pickle.load(f)\n",
    "        \n",
    "    # Get the weighted average stats for home and away teams\n",
    "    home_stats = team_stats[team_stats['Team'] == home_team].iloc[:, 1:].values.flatten()\n",
    "    away_stats = team_stats[team_stats['Team'] == away_team].iloc[:, 1:].values.flatten()\n",
    "    \n",
    "    # Get the win streaks\n",
    "    team_win_streak = win_streaks.loc[away_team, home_team].flatten()\n",
    "    home_venue_streak = venue_streaks.loc[home_team, venue].flatten()\n",
    "    away_venue_streak = venue_streaks.loc[away_team, venue].flatten()\n",
    "    home_team_form = team_form.loc[team_form['Team'] == home_team, 'Current.Form'].values[0].flatten()\n",
    "    away_team_form = team_form.loc[team_form['Team'] == home_team, 'Current.Form'].values[0].flatten()\n",
    "    \n",
    "    weather_dict[weather] = 1\n",
    "    # Convert the dictionary to a DataFrame (single row)\n",
    "    weather_df = pd.DataFrame([weather_dict]).values.flatten()\n",
    "    \n",
    "    # Combine all features into a single array\n",
    "    features = np.concatenate([\n",
    "    home_stats, home_team_form,\n",
    "    away_stats, away_team_form,\n",
    "    home_venue_streak,away_venue_streak,team_win_streak,\n",
    "    weather_df\n",
    "    ])\n",
    "\n",
    "    column_names = match_results.drop(columns=['match.homeTeam.name', 'match.awayTeam.name','venue.name','Margin','Result','weather.weatherType',\n",
    "                                          'Home.Team.Venue.Win.Streak', 'Away.Team.Venue.Win.Streak','Home.Win.Streak']).columns  # Replace with actual feature names\n",
    "    column_names = column_names.append(pd.Index(['Home.Team.Venue.Win.Streak', 'Away.Team.Venue.Win.Streak','Home.Win.Streak'])).append(pd.Index(weather_categories))\n",
    "\n",
    "\n",
    "    new_data_df = pd.DataFrame(features.reshape(1, -1), columns=column_names)\n",
    "\n",
    "    features = preprocessor.transform(new_data_df)  # Normalize features\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02458386-33a5-43e0-8163-d30a1a861db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(home_team, away_team, venue, weather):\n",
    "    with open('accuracy.pkl', 'rb') as f:\n",
    "        a = pickle.load(f)\n",
    "\n",
    "    # Load RandomForest model\n",
    "    rf_model = joblib.load('rf_model.pkl')\n",
    "\n",
    "    # Load XGBoost model\n",
    "    xgb_model = joblib.load('xgb_model.pkl')\n",
    "\n",
    "    # Load the neural network model\n",
    "    nn_model_full = load_model('nn_model.h5')\n",
    "\n",
    "    # Load the meta-model (Logistic Regression)\n",
    "    meta_model_full = joblib.load('meta_model.pkl')\n",
    "\n",
    "    with open('encoder.pkl', 'rb') as f:\n",
    "        encoder = pickle.load(f)\n",
    "    \n",
    "    features = extract_features(home_team, away_team, venue,weather)\n",
    "\n",
    "    rf_predictions_new = rf_model.predict_proba(features)\n",
    "    xgb_predictions_new = xgb_model.predict_proba(features)\n",
    "    nn_predictions_new = nn_model_full.predict(features)\n",
    "\n",
    "    # Stack predictions to form meta-features\n",
    "    meta_features_new = np.hstack([rf_predictions_new, xgb_predictions_new, nn_predictions_new])\n",
    "\n",
    "    # Get final ensemble prediction\n",
    "    final_prediction = meta_model_full.predict_proba(meta_features_new)\n",
    "    \n",
    "    #prediction_probs = model.predict(features)[0]\n",
    "    predicted_class_index = np.argmax(final_prediction)\n",
    "    predicted_class = encoder.inverse_transform([predicted_class_index])[0]  # Decode the prediction\n",
    "    max_prob = final_prediction[0][predicted_class_index]  # Get the maximum probability and its corresponding class\n",
    "    acc = max_prob * a\n",
    "    max_prob_percent = f\"{acc * 100:.2f}%\"\n",
    "    market = f\"{round_decimals_up(1 / acc,2):.2f}\"\n",
    "\n",
    "    return predicted_class,max_prob_percent,market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf294bc-1a7e-4a0e-8893-eb2fa1d4bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_predictions():\n",
    "    preds = []\n",
    "    for h,a,v,w in zip(list(fixture['home.team.name']),\n",
    "                                             list(fixture['away.team.name']),\n",
    "                                             list(fixture['venue.name']),\n",
    "                                             list(fixture['Next_round_weather'])):\n",
    "        (r,p,m)=make_prediction(h,a,v,w)\n",
    "\n",
    "        if r == \"BW\":\n",
    "            r = f'{h} 40+'\n",
    "        if r == \"LW\":\n",
    "            r = f'{h} 1-39'\n",
    "        if r == \"LL\":\n",
    "            r = f'{a} 1-39'\n",
    "        if r == \"BL\":\n",
    "            r = f'{a} 40+'\n",
    "        if r == \"D\":\n",
    "            r = f'draw'\n",
    "    \n",
    "        new = {\"Match\": f\"{h} vs {a}\", \"Venue\": f\"{v}\" , \"Prediction\": f\"{r}\",\n",
    "             \"Market\": f\"${m}\", \"Probability\": f\"{p}\"}\n",
    "        preds.append(new)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a30773f5-bfbb-46b1-8d56-136cf549ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_predictions_json():\n",
    "    # Prepare data for JSON\n",
    "    output_data = p\n",
    "    \n",
    "\n",
    "    # Save to JSON\n",
    "    with open(f'predictions.json', 'w') as f:\n",
    "        json.dump(output_data, f, indent=4)\n",
    "    print(f'Predictions saved to predictions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a9933e4-2c4c-42cf-aac8-10611322609d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 223ms/step\n",
      "Predictions saved to predictions.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    cleaned_data,website_code=set_wd()\n",
    "    weather_categories = ['CLEAR_NIGHT','MOSTLY_SUNNY','OVERCAST','RAIN','SUNNY','THUNDERSTORMS','WINDY']  # Add all weather types you used\n",
    "    # Create a dictionary where all categories are 0\n",
    "    weather_dict = {category: 0 for category in weather_categories}\n",
    "    \n",
    "    match_results, team_stats, win_streaks, venue_streaks, team_form, fixture = load_data()\n",
    "\n",
    "    p = gen_predictions()\n",
    "    output_predictions_json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
